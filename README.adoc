:doctype: book
:toc: left
:toclevels: 3
:toc: macro
:sectnums:
:icons: font
:source-highlighter: highlightjs
:idprefix:
:idseparator: -
:sectlinks:
:sectanchors:
:linkcss: false

// Vars
:project-group-id: org.bonitasoft.connectors
:project-artifact-id: bonita-connector-openai
:project-version: 1.0.0-SNAPSHOT
:orga: bonitasoft
:uri-org: https://github.com/{orga}
:uri-repo: {uri-org}/{project-artifact-id}
:short-bonita-version: 10.2
:doc-url: https://documentation.bonitasoft.com/bonita/{short-bonita-version}
:java-version: 17
= bonita-connector-openai

image:bonitasoft-community.png[Bonitasoft,link="https://www.bonitasoft.com",width=250px]
image:src/main/resources/openai@2x.png[OpenAI,link="https://openai.com"]

image:{uri-repo}/actions/workflows/build.yaml/badge.svg[Build,link="{uri-repo}/actions?query=build"]



The project **bonita-connector-openai** is a set of Bonita Connectors for **Bonita {short-bonita-version}**  **Community** version written in `java` language.

The connectors allow to interact with OpenAI chat models by sending prompt and documents and returning the generated output.

[WARNING]
====
The connector is still under development and current state is just a draft version.
====

toc::[]

== Getting started

To use this connector, add it as a dependency to your Bonita process.
For more details on Bonita Connector please refer to {doc-url}/connector-archetype[documentation]

[source,xml,subs="attributes+"]
----
<dependency>
    <groupId>org.bonitasoft.connectors</groupId>
    <artifactId>bonita-connector-openai</artifactId>
    <version>{project-version}</version>
</dependency>
----

=== Common configuration

[caption=Configuration,options=autowidth]
|===
|Parameter name |Required |Description |Default value

|*apiKey*
|false
|The OpenAI API key. Parameter is optional for testing purpose but obviously required with official OpenAI endpoint. The connector will use the system environment variable named OPENAI_API_KEY then the provided parameter and at last a dummy `changeMe` value.
| changeMe

|*url*
|false
|The OpenAI endpoint url. This parameter allows to use an alternate endpoint for tests.
|Default to the official OpenAI endpoint

|*requestTimeout*
|false
|The request timeout in milliseconds for OpenAI calls.
|null

|*chatModelName*
|false
|The model to use for chat like gpt-4, gpt-4o-mini, lama, ... See OpenAI documentation at https://platform.openai.com/docs/models/models for detailed information about models.
|gpt-4o-mini

|*modelTemperature*
|false
|The temperature to use for the model. Higher values will result in more creative responses. Must be between 0 and 1. Leave blank if the selected model does not support this parameter. If parameter is not present, the temperature will not be set in chat context.
|null
|===


== Connectors

=== Ask connector

Take a user prompt and send it to OpenAI then return the AI response. The prompt text can ask question about a provided process document.

[caption=Configuration,options=autowidth]
|===
|Parameter name |Required |Description |Default value

|*systemPrompt*
|false
|The system prompt to pass to the OpenAI endpoint.  It helps to influence the behavior of the assistant and specify a default context. (ex: You are a personal finance advisor, providing guidance, etc.)
|"You are a polite Assistant"

|*userPrompt*
|*true*
|The user prompt content to send to the AI provider
|

|*sourceDocumentRef*
|false
|The reference to the process document to load and add to the user prompt. If not null, the connector will try to read the specified document and send it as an attachment to the user prompt. Format supported are "doc", "docx", "pdf", "png", "jpg", "jpeg", ... (see https://tika.apache.org/3.1.0/formats.html)
|null

|*outputJsonSchema*
|false
|The JSON schema that represent how to structure the JSON connector output.
|null

|===

The result can be a simple JSON object or one compliant with a provided JSON schema.
This result will be placed as a map entry of type `java.lang.String` for the key named *output*.

=== Extract connector

This connector allow extracting information from a bonita document.

[caption=Configuration,options=autowidth]
|===
|Parameter name |Required |Description |Default value

|*sourceDocumentRef*
|*true*
|The reference to the process document to load and add to the user prompt. If not null, the connector will try to read the specified document  and send it as an attachment to the user prompt. Format supported are "doc", "docx", "pdf", "png", "jpg", "jpeg", ... (see https://tika.apache.org/3.1.0/formats.html)
|null

|*fieldsToExtract*
|false
|The list of fields to extract from the given document. The connector expect a list of String (like `List.of("firstName","lastName","address")`.
|null

|*outputJsonSchema*
|false
|The JSON schema that represent how to structure the JSON connector output. If a JSON schema is specified, the `fieldsToExtract` parameter is ignored.
|null

|===

IMPORTANT: You must provide at least one of `fieldsToExtract` or `outputJsonSchema` parameters.

The result can be a simple JSON object or one compliant with a provided JSON schema.
This connector result will be placed as a map entry of type `java.lang.String` for the key named *output*.

=== Classify connector

This connector allow to classify a bonita process document according to a list of category provided by the user.

[caption=Configuration,options=autowidth]
|===
|Parameter name |Required |Description |Default value

|*sourceDocumentRef*
|*true*
|The reference to the process document to load and add to the user prompt. If not null, the connector will try to read the specified document  and send it as an attachment to the user prompt. Format supported are "doc", "docx", "pdf", "png", "jpg", "jpeg", ... (see https://tika.apache.org/3.1.0/formats.html)
|null

|*categories*
|*true*
|The list of category used to classify the given document. The connector expect a list of String (like `List.of("RIB","ID",...)`.
It is recommended to add a default category if none other matches such as `Unknown`
|null

|===


The result is a JSON String such as the following sample.

.sample classification result
[source,json]
----
{
  "category": "xxx",
  "confidence": 0.9
}
----

The confidence score is defined as :

- [0.0..0.3]: Very uncertain or guessing
- [0.3..0.6]: Some uncertainty, potential ambiguity exists
- [0.6..0.8]: Reasonably certain, minor doubt
- [0.8..1.0]: Very certain, no doubt

This connector result will be placed as a map entry of type `java.lang.String` for the key named *output*.

== Developing
// _**TODO**_: Here's a brief introduction about what a developer must do in order to start developing the project further:

Prerequisite:

- Java ( **jdk {java-version}** or higher)
- Maven (optional if you chose to use https://github.com/takari/maven-wrapper[maven wrapper script] as archetype option)
- A Git client (optional but highly recommended)
- Docker and docker compose for integration tests

=== Building
// _**TODO**_: If your project needs some additional steps for the developer to build the project after some code changes, state them here:
The project is a standard maven project. For more details about Apache Maven, please refer to the https://maven.apache.org/guides/getting-started/[documentation]

[source,bash]
----
git clone https://your.github.com/bonita-connector-openai.git
cd bonita-connector-openai/
./mwnw package
----

The build should produce a jar archive under the `target/` folder named `bonita-connector-openai-{project-version}.jar`


=== Run integration tests

// _**TODO**_: Here again you should state what actually happens when the code above gets executed.

The connector needs an OpenAI endpoint up & running. A docker compose file is present in the root folder which starts
a https://ollama.com/[ollama] container that you can use as a local replacement of OpenAI provider.

Just issue `docker compose up -d` and ollama API will be available at `http://localhost:11434/v1`

NOTE: To download model use the following command `docker compose exec ollama bash -c 'ollama pull <model name>'`.  You can check the logs with `docker compose logs -f ollama` for more info.

Once ollama is ready, you can run integration tests using standard maven command and activating a dedicated maven profile (ITs)

`./mvnw verify -PITs`

=== Deploying / Publishing

// _**TODO**_: In case there's some step you have to take that publishes this project to a server, this is the right time to state it.

{doc-url}/managing-extension-studio[Install the connector in your Bonita project using the Studio, window = "_blank"].

// == Contributing
//
// // _**TODO**_: Make easy to your team to jump in and start contributing to your project.
//
// These paragraphs are meant to welcome those kind souls to feel that they are
// needed. You should state something like:
//
// "If you'd like to contribute, please fork the repository and use a feature
// branch. Pull requests are warmly welcome."
//
// If there's anything else the developer needs to know (e.g. the code style
// guide), you should link it here. If there's a lot of things to take into
// consideration, it is common to separate this section to its own file called
// `CONTRIBUTING.adoc` (or similar). If so, you should say that it exists here.

== Links

// _**TODO**_: Even though this information can be found inside the project on machine-readable
// format like in a .json file, it's good to include a summary of most useful
// links to humans using your project. You can include links like:

. Project homepage: https://github.com/bonitasoft-labs/bonita-connector-openai
. Repository: https://github.com/bonitasoft-labs/bonita-connector-openai
. Issue tracker: https://github.com/bonitasoft-labs/bonita-connector-openai/issues
// .. In case of sensitive bugs like security vulnerabilities, please contact
//     my@email.com directly instead of using issue tracker. We value your effort
//     to improve the security and privacy of this project!
